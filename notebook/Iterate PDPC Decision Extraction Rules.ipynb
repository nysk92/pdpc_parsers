{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate Extraction Rules of PDPC Decisions Key Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scope: Protection Obligation\n",
    "\n",
    "1) Date of Decision\n",
    "\n",
    "2) Factual matrix\n",
    "- Entities (Parties)\n",
    "- Incidents and Complaints\n",
    "- Factual Paragraphs: look for dates\n",
    "- Type of Personal Data \n",
    "\n",
    "3) Aggravating or mitigating factors\n",
    "\n",
    "4) Directions given\n",
    "\n",
    "5) Breach or no breach\n",
    "- If direction found (including warning) there is breach\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_pdf(filename):\n",
    "    pdfFileObj = open(filename, 'rb')\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    pdf_lines = []\n",
    "    number_of_pages = pdfReader.numPages\n",
    "    for i in range(number_of_pages):\n",
    "        pageObj = pdfReader.getPage(i)\n",
    "        pdf_lines.append(pageObj.extractText())\n",
    "    content = ''.join(pdf_lines)\n",
    "    result = {\"pages\": number_of_pages,\n",
    "             \"lines\": pdf_lines,\n",
    "             \"content\": content}\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = file_to_pdf('samplepdpc.pdf')\n",
    "# sample_content = sample[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break File into Paragraps and Clean Line Breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break Content in Paragraphs as List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_and_clean(mess):\n",
    "    paras = []\n",
    "    start_line = 1\n",
    "    start_line_re = r\"\\n\" + str(start_line) + r\"?\\.\\n\"\n",
    "    while re.findall(start_line_re, mess) != []:\n",
    "        paras.append(re.split(start_line_re, mess, maxsplit=1)[0])\n",
    "        mess = re.split(start_line_re, mess, maxsplit=1)[1]\n",
    "        start_line = start_line + 1\n",
    "        start_line_re = r\"\\n\" + str(start_line) + r\"?\\.\\n\"\n",
    "    paras.append(mess)\n",
    "    return [para.replace(\"\\n\\n\", \"##\").replace(\"\\n\", \"\") for para in paras]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have Entire Content as String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(content):\n",
    "    return content.replace(\"\\n\\n\", \"##\").replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to test individual functions on a sample file\n",
    "# test_content = clean_content(sample_content)\n",
    "# test_paras = para_and_clean(sample_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_RX = re.compile(r\"(?:\\d{1,2})\\s(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s(?:\\d{1,4})\", flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(content):\n",
    "    \"Get the first date mentioned in the Decision, which is the Decision date.\"\n",
    "    if DATE_RX.search(content):\n",
    "        return DATE_RX.search(content).group()\n",
    "    else:\n",
    "        return \"date not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Factual Elements\n",
    "\n",
    "Entities: \"(1)...Respondents\", \"(1)...Organisations\", if not Organisation\"\n",
    "\n",
    "Incident: \"Incident\"/first mention of \"the incident\"\n",
    "\n",
    "Factual Paragraphs: What led to incident -> look for dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities_top(content):\n",
    "    \"Get entities mentioned as parties at the top of the Decision.\"\n",
    "    if \"... Organisations\" in content:\n",
    "        focus_area = content.split(\"... Organisations\")[0]\n",
    "    elif \"... Respondents\" in content:\n",
    "        focus_area = content.split(\"... Respondents\")[0]\n",
    "    else:\n",
    "        return []\n",
    "    candidates = re.split(r\"\\s\\(\\d{1}\\)\", focus_area)\n",
    "    return [en.strip() for en in candidates[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities_txt(content):\n",
    "    \"Get single entity mentioned in content refered to as Organisation.\"\n",
    "    if \"##Organisation\" in content:\n",
    "        focus_area = content.split(\"##Organisation\")[0]\n",
    "        focus_area = focus_area[-100:].replace(\"##\", \"\")\n",
    "        ent_list = []\n",
    "        for wrd in [x.strip() for x in focus_area.split(\" \")[::-1] if x!=\"\"]:\n",
    "            ## iterate to cut off at small letter\n",
    "            if wrd.istitle():\n",
    "                ent_list.append(wrd)\n",
    "            elif len(ent_list) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        return [\" \".join(ent_list[::-1])]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(content):\n",
    "    \"Returns list of entities detected.\"\n",
    "    entities = get_entities_top(content)\n",
    "    if entities != []:\n",
    "        return entities\n",
    "    else:\n",
    "        return get_entities_txt(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Incident Paragaphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incidents(paras):\n",
    "    return [p for p in paras if bool(re.search(\"incident\", p, flags=re.I))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complaint(paras):\n",
    "    return [p for p in paras if bool(re.search(\"complainant|complaint|complain\", p, flags=re.I))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_incidents(paras):\n",
    "    return get_incidents(paras) + get_complaint(paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Factual Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_personal_data(paras):\n",
    "    \"Get paragraphs mentioning types of personal data.\"\n",
    "    return [p for p in paras if bool(re.search(\"\\bid\\b|name|contact|email|address|NRIC\", p, flags=re.I))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factual(paras):\n",
    "    \"Get paragraphs describing what happened at each date.\"\n",
    "    return [p for p in paras if DATE_RX.search(p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggravating or Mitigating Factors\n",
    "\n",
    "“aggravating|mitigating|factors|considerations”\n",
    "if too general, look for listing pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_am_factors(paras):\n",
    "    \"Get paragraphs on aggravating or mitigating factors.\"\n",
    "    return [p for p in paras if bool(re.search(\"aggravating|mitigating|factors|considerations\", p, flags=re.I))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directions and Breach\n",
    "\n",
    "Directions given: \"hereby directs\"/\"Commission directs\"/\"Commissioner directs\" + money amount / \"decided to issue|give a [Ww]arning\"\n",
    "\n",
    "Breach or no breach: if direction found (including warning) there is breach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directions_and_breach(paras):\n",
    "    db_paras = [p for p in paras if bool(re.search(\"hereby directs|commission directs|commissioner directs|decided to issue|give a warning\", p, flags=re.I))]\n",
    "    if db_paras == []:\n",
    "        return \"No Breach\"\n",
    "    else:\n",
    "        return db_paras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_decision_data(filepath):\n",
    "    \"Takes in a PDF and outputs a dictionary of extracted results.\"\n",
    "    decision = file_to_pdf(filepath)\n",
    "    content = sample[\"content\"]\n",
    "    content = clean_content(content)\n",
    "    paras = para_and_clean(content)\n",
    "    return {\n",
    "        \"decision date\": get_date(content),\n",
    "        \"entities\": get_entities(content),\n",
    "        \"directions and breach\": get_directions_and_breach(paras),\n",
    "        \"aggravating and mitigating factors\": get_am_factors(paras),\n",
    "        \"entities\": get_entities(content),\n",
    "        \"personal data\": get_personal_data(paras),\n",
    "        \"incidents\": get_all_incidents(paras),\n",
    "        \"facts\": get_factual(paras)\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
